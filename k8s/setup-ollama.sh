#!/bin/bash

# Setup Ollama in Kubernetes for News Summarizer
# This script:
# 1. Creates Ollama deployment
# 2. Pulls Mistral 7B model
# 3. Updates main deployment to use Ollama

set -e

echo "ğŸš€ Setting up Ollama in Kubernetes"
echo "===================================="
echo ""

# Check if kubectl is available
if ! command -v kubectl &> /dev/null; then
    echo "âŒ Error: kubectl is not installed or not in PATH"
    exit 1
fi

# Check if minikube is running (or any k8s cluster)
if ! kubectl cluster-info &> /dev/null; then
    echo "âŒ Error: Kubernetes cluster is not accessible"
    echo "   Make sure minikube is running: minikube start"
    exit 1
fi

echo "âœ… Kubernetes cluster is accessible"
echo ""

# Step 1: Deploy Ollama
echo "ğŸ“¦ Step 1: Deploying Ollama..."
kubectl apply -f k8s/ollama-deployment.yaml

echo "â³ Waiting for Ollama to be ready..."
kubectl wait --for=condition=available deployment/ollama --timeout=300s || {
    echo "âš ï¸  Ollama deployment taking longer than expected"
    echo "   Check status: kubectl get pods -l app=ollama"
}

echo "âœ… Ollama deployed"
echo ""

# Step 2: Wait for Ollama pod to be ready
echo "â³ Waiting for Ollama pod to be ready..."
OLLAMA_POD=$(kubectl get pod -l app=ollama -o jsonpath='{.items[0].metadata.name}')
kubectl wait --for=condition=ready pod/$OLLAMA_POD --timeout=300s

echo "âœ… Ollama pod is ready"
echo ""

# Step 3: Pull Mistral 7B model
echo "ğŸ“¥ Step 2: Pulling Mistral 7B model (~4GB, this may take 5-10 minutes)..."
echo "   This is a one-time download"
echo ""

kubectl exec $OLLAMA_POD -- ollama pull mistral:7b

echo ""
echo "âœ… Mistral 7B model downloaded"
echo ""

# Step 4: Verify model is available
echo "ğŸ” Step 3: Verifying model..."
kubectl exec $OLLAMA_POD -- ollama list | grep mistral:7b || {
    echo "âš ï¸  Warning: Mistral model not found in list"
}

echo "âœ… Model verification complete"
echo ""

# Step 5: Update main deployment
echo "ğŸ”„ Step 4: Updating News Summarizer deployment to use Ollama..."
echo "   Options:"
echo "   1. Use deployment-with-ollama.yaml (recommended)"
echo "   2. Update existing deployment.yaml manually"
echo ""
read -p "Update deployment now? (y/n): " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ“ Applying updated deployment..."
    kubectl apply -f k8s/deployment-with-ollama.yaml
    
    echo "â³ Waiting for deployment rollout..."
    kubectl rollout status deployment/newssummariser --timeout=300s
    
    echo "âœ… Deployment updated"
else
    echo "â„¹ï¸  Skipping deployment update"
    echo "   You can update manually later"
fi

echo ""
echo "===================================="
echo "âœ… Setup Complete!"
echo "===================================="
echo ""
echo "ğŸ“Š Status:"
kubectl get pods -l app=ollama
echo ""
kubectl get pods -l app=newssummariser
echo ""
echo "ğŸ§ª Test Ollama:"
echo "   kubectl exec -it $OLLAMA_POD -- ollama run mistral:7b \"Test\""
echo ""
echo "ğŸ“ Next Steps:"
echo "   1. Your app is now using Ollama instead of OpenAI"
echo "   2. Check logs: kubectl logs -f deployment/newssummariser"
echo "   3. Monitor Ollama: kubectl logs -f deployment/ollama"
echo ""

